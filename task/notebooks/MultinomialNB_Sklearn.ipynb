{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Libraries",
   "id": "f9626013d915f048"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T11:52:48.066628Z",
     "start_time": "2025-03-03T11:52:48.054068Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Berkay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Berkay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Berkay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preprocessing",
   "id": "32c99c615fedaadf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:52:48.819413Z",
     "start_time": "2025-03-03T11:52:48.066628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "df.head()"
   ],
   "id": "ce30389c6e843be6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:52:48.841340Z",
     "start_time": "2025-03-03T11:52:48.819413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert sentiment values to numerical (1 for positive, 0 for negative)\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
   ],
   "id": "2319cb208c65024d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:52:50.191383Z",
     "start_time": "2025-03-03T11:52:48.841340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Text preprocessing: Remove HTML tags, URLs, convert to lowercase, and remove punctuation\n",
    "df['review'] = (\n",
    "    df['review']\n",
    "    .str.replace(r'<[^<>]*>', '', regex=True)  # Remove HTML tags\n",
    "    .str.replace(r'https?://\\S+|www\\.\\S+', '', regex=True)  # Remove URLs\n",
    "    .str.lower()  # Convert text to lowercase\n",
    "    .str.replace(f\"[{string.punctuation}]\", '', regex=True)  # Remove punctuation\n",
    ")"
   ],
   "id": "f5b942edfe54d2b7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:53:16.004986Z",
     "start_time": "2025-03-03T11:52:50.191383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords and apply lemmatization\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['review'] = df['review'].apply(\n",
    "    lambda x: ' '.join(\n",
    "        lemmatizer.lemmatize(word) for word in tokenizer.tokenize(x) if word not in stop_words\n",
    "    )\n",
    ")"
   ],
   "id": "756d1f0b4ab6cfcb",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:53:16.014405Z",
     "start_time": "2025-03-03T11:53:16.004986Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "25695eff1619817e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one reviewer mentioned watching 1 oz episode y...          1\n",
       "1  wonderful little production filming technique ...          1\n",
       "2  thought wonderful way spend time hot summer we...          1\n",
       "3  basically there family little boy jake think t...          0\n",
       "4  petter matteis love time money visually stunni...          1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classifier",
   "id": "7078b0f1ded88c25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:53:16.030913Z",
     "start_time": "2025-03-03T11:53:16.016435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train, test = train_test_split(df, test_size = 0.25, random_state = 42)\n",
    "\n",
    "X_train, y_train = train['review'], train['sentiment']\n",
    "X_test, y_test = test['review'], test['sentiment']"
   ],
   "id": "d9268b7933415467",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:53:21.149859Z",
     "start_time": "2025-03-03T11:53:16.030913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "x_train_vector = tfidf.fit_transform(X_train)\n",
    "\n",
    "x_test_vector = tfidf.transform(X_test)"
   ],
   "id": "fcb642196976a811",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:53:21.213363Z",
     "start_time": "2025-03-03T11:53:21.149859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multi_clf = MultinomialNB()\n",
    "multi_clf.fit(x_train_vector, y_train.values)\n",
    "\n",
    "predict_NB = multi_clf.predict(x_test_vector)"
   ],
   "id": "c134f7f74b7240ce",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:53:21.234022Z",
     "start_time": "2025-03-03T11:53:21.213363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Classification Report: \\n\\n\", classification_report(y_test, predict_NB))\n",
    "print(\"Confusion Matrix: \\n\\n\", confusion_matrix(y_test, predict_NB))\n",
    "print(\"Accuracy: \\n\\n\", accuracy_score(y_test, predict_NB))"
   ],
   "id": "aae104e8f3c038b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      6157\n",
      "           1       0.88      0.84      0.86      6343\n",
      "\n",
      "    accuracy                           0.87     12500\n",
      "   macro avg       0.87      0.87      0.87     12500\n",
      "weighted avg       0.87      0.87      0.87     12500\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      " [[5459  698]\n",
      " [ 988 5355]]\n",
      "Accuracy: \n",
      "\n",
      " 0.86512\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Libraries",
   "id": "7b508d51d23633d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:13.030136Z",
     "start_time": "2025-03-03T11:54:33.634843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from app import Flask, request, jsonify"
   ],
   "id": "33aebb768ee36542",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preprocessing",
   "id": "25a352b7d95987cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:13.849504Z",
     "start_time": "2025-03-03T11:55:13.030136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
   ],
   "id": "803d81e5f0c8da7f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:51.522012Z",
     "start_time": "2025-03-03T11:55:13.849504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<[^<>]*>', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = WhitespaceTokenizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join(lemmatizer.lemmatize(word) for word in tokenizer.tokenize(text) if word not in stop_words)\n",
    "\n",
    "df['review'] = df['review'].apply(preprocess_text)"
   ],
   "id": "62166b5f582dfffa",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:51.548249Z",
     "start_time": "2025-03-03T11:55:51.522012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split dataset\n",
    "train, test = train_test_split(df, test_size=0.25, random_state=42)\n",
    "X_train, y_train = train['review'], train['sentiment']\n",
    "X_test, y_test = test['review'], test['sentiment']"
   ],
   "id": "2e27d8fe05e4e861",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classifier",
   "id": "8830eee3ea65cc50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prior",
   "id": "9a02c6b867a86f08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:54.168338Z",
     "start_time": "2025-03-03T11:55:51.548249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build Vocabulary\n",
    "vocab = set()\n",
    "word_counts = defaultdict(lambda: [0, 0])  # {word: [neg_count, pos_count]}\n",
    "class_doc_counts = [0, 0]  # [neg_class_count, pos_class_count]\n",
    "\n",
    "for text, label in zip(X_train, y_train):\n",
    "    words = text.split()\n",
    "    class_doc_counts[label] += 1  # Count number of documents per class\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "        word_counts[word][label] += 1\n",
    "\n",
    "vocab_size = len(vocab)"
   ],
   "id": "5d95c97901c0aaf3",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:54.176661Z",
     "start_time": "2025-03-03T11:55:54.168338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute Prior Probabilities\n",
    "prior_A = class_doc_counts[0] / sum(class_doc_counts)  # P(A)\n",
    "prior_B = class_doc_counts[1] / sum(class_doc_counts)  # P(B)\n",
    "prior_A, prior_B"
   ],
   "id": "e082f432a797b9d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.50248, 0.49752)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculating coefficients",
   "id": "4ba1e3e84a297005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:54.391705Z",
     "start_time": "2025-03-03T11:55:54.178684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_words_per_class = {\n",
    "    0: sum(word_counts[w][0] for w in vocab),\n",
    "    1: sum(word_counts[w][1] for w in vocab)\n",
    "}\n",
    "\n",
    "def compute_prob(word, label):\n",
    "    word_count = word_counts[word][label]  \n",
    "    total_words_in_class = total_words_per_class[label] \n",
    "    vocab_size = len(vocab)  \n",
    "    \n",
    "    return (word_count + 1) / (total_words_in_class + vocab_size)\n"
   ],
   "id": "1ecae0da81fc4545",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predict",
   "id": "f1c914ef020598e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:54.398881Z",
     "start_time": "2025-03-03T11:55:54.391705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(text):\n",
    "    words = text.split()\n",
    "    log_prob_0 = prior_A\n",
    "    log_prob_1 = prior_B\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            log_prob_0 += np.log(compute_prob(word, 0))\n",
    "            log_prob_1 += np.log(compute_prob(word, 1))\n",
    "    \n",
    "    return 1 if log_prob_1 > log_prob_0 else 0"
   ],
   "id": "838f2a2b5696bbd0",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:58.769592Z",
     "start_time": "2025-03-03T11:55:54.398881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = [predict(text) for text in X_test]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Accuracy: \\n\", accuracy_score(y_test, predictions))"
   ],
   "id": "937074ef4dcc1cac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      6157\n",
      "           1       0.88      0.85      0.86      6343\n",
      "\n",
      "    accuracy                           0.86     12500\n",
      "   macro avg       0.86      0.86      0.86     12500\n",
      "weighted avg       0.86      0.86      0.86     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5399  758]\n",
      " [ 981 5362]]\n",
      "Accuracy: \n",
      " 0.86088\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T11:55:58.785597Z",
     "start_time": "2025-03-03T11:55:58.771598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add predictions to DataFrame for analysis\n",
    "test_results = pd.DataFrame({\n",
    "    'review': X_test,\n",
    "    'actual_sentiment': y_test,\n",
    "    'predicted_sentiment': predictions\n",
    "})\n",
    "\n",
    "# Display results\n",
    "test_results.head(20)"
   ],
   "id": "30a4f11f8c9ba699",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review  actual_sentiment  \\\n",
       "33553  really liked summerslam due look arena curtain...                 1   \n",
       "9427   many television show appeal quite many differe...                 1   \n",
       "199    film quickly get major chase scene ever increa...                 0   \n",
       "12447  jane austen would definitely approve onegwynet...                 1   \n",
       "39489  expectation somewhat high went see movie thoug...                 0   \n",
       "42724  ive watched movie fairly regular basis life ne...                 1   \n",
       "10822  story hope highlighted tragic reality youth fa...                 1   \n",
       "49498  okay didnt get purgatory thing first time watc...                 1   \n",
       "4144   disappointed series lot cool graphic thats lev...                 0   \n",
       "36958  first 30 minute tinseltown finger teetering re...                 0   \n",
       "43106  jeez immensely boring leading man christian sc...                 0   \n",
       "38695  great great west coast got dirty harry callaha...                 1   \n",
       "6188   made 2007 cg bad movie made 1998 one part movi...                 0   \n",
       "1414   movie stink majorly reason gave 3 graphic semi...                 0   \n",
       "18471  start wooden acting film disaster grown ny tel...                 0   \n",
       "29282  movie start somewhat slowly get running toward...                 1   \n",
       "15177  slightly uneven entry one standout sequence in...                 1   \n",
       "34304  first introduced john water film seeing female...                 1   \n",
       "12609  movie good acting virtually cast gripping stor...                 1   \n",
       "12144  cant help notice negative review movie gotten ...                 1   \n",
       "\n",
       "       predicted_sentiment  \n",
       "33553                    1  \n",
       "9427                     1  \n",
       "199                      0  \n",
       "12447                    1  \n",
       "39489                    0  \n",
       "42724                    1  \n",
       "10822                    1  \n",
       "49498                    0  \n",
       "4144                     0  \n",
       "36958                    0  \n",
       "43106                    0  \n",
       "38695                    1  \n",
       "6188                     0  \n",
       "1414                     0  \n",
       "18471                    0  \n",
       "29282                    1  \n",
       "15177                    1  \n",
       "34304                    1  \n",
       "12609                    1  \n",
       "12144                    0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>actual_sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>really liked summerslam due look arena curtain...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>many television show appeal quite many differe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>film quickly get major chase scene ever increa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>jane austen would definitely approve onegwynet...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>expectation somewhat high went see movie thoug...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42724</th>\n",
       "      <td>ive watched movie fairly regular basis life ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10822</th>\n",
       "      <td>story hope highlighted tragic reality youth fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49498</th>\n",
       "      <td>okay didnt get purgatory thing first time watc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>disappointed series lot cool graphic thats lev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36958</th>\n",
       "      <td>first 30 minute tinseltown finger teetering re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43106</th>\n",
       "      <td>jeez immensely boring leading man christian sc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38695</th>\n",
       "      <td>great great west coast got dirty harry callaha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>made 2007 cg bad movie made 1998 one part movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>movie stink majorly reason gave 3 graphic semi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18471</th>\n",
       "      <td>start wooden acting film disaster grown ny tel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29282</th>\n",
       "      <td>movie start somewhat slowly get running toward...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15177</th>\n",
       "      <td>slightly uneven entry one standout sequence in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34304</th>\n",
       "      <td>first introduced john water film seeing female...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>movie good acting virtually cast gripping stor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12144</th>\n",
       "      <td>cant help notice negative review movie gotten ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
